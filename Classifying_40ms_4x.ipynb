{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "##complex data와 똑같이 40ms로 parsing했음 데이터 4배라고 생각하고 뻥튀기시켜봄 정확도는 10ms와 비슷하게 나옴\n",
    "\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "from scipy import signal\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import re\n",
    "\n",
    "#filename queue\n",
    "filename_queue=glob.glob('./rawdata/data[1-5].csv')\n",
    "\n",
    "#Create return path\n",
    "return_path='./rawdata/data.csv'\n",
    "create_file=open(return_path,'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-511918b9194c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#index=[1,2,3,11,14]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mlabel_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtraininglabel_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtestlabel_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#Parsing data\n",
    "\n",
    "training_set=[]\n",
    "test_set=[]\n",
    "training_label=[]\n",
    "test_label=[]\n",
    "#index=[1,2,3,11,14]\n",
    "index=[1,2,3]\n",
    "label_count=np.zeros(17)\n",
    "traininglabel_count=np.zeros(17)\n",
    "testlabel_count=np.zeros(17)\n",
    "n_data=[]\n",
    "\n",
    "#read file from filename queue\n",
    "for filename in filename_queue:\n",
    "    file=open(filename, newline='')\n",
    "    \n",
    "    reader=csv.reader(file)\n",
    "    header=next(reader)\n",
    "    \n",
    "    for row in reader:\n",
    "        row[4:]=[float(i) for i in row[4:]]\n",
    "        labl=int(row[3])\n",
    "\n",
    "        label_count[labl]+=4\n",
    "        if labl not in index:\n",
    "            for x in range(4):\n",
    "                \n",
    "                #Extract sensor data and smoothing\n",
    "                X_acc=list(row[4*i+4+x] for i in range(150))\n",
    "                X_acc=signal.savgol_filter(X_acc,5,3)\n",
    "                \n",
    "                Y_acc=list(row[4*i+604+x] for i in range(150))\n",
    "                Y_acc=signal.savgol_filter(Y_acc,5,3)\n",
    "                \n",
    "                Z_acc=list(row[4*i+1204+x] for i in range(150))\n",
    "                Z_acc=signal.savgol_filter(Z_acc,5,3)\n",
    "                \n",
    "                X_gyro=list(row[4*i+1804+x] for i in range(150))\n",
    "                X_gyro=signal.savgol_filter(X_gyro,5,3)\n",
    "                \n",
    "                Y_gyro=list(row[4*i+2404+x] for i in range(150))\n",
    "                Y_gyro=signal.savgol_filter(Y_gyro,5,3)\n",
    "                \n",
    "                Z_gyro=list(row[4*i+3004+x] for i in range(150))\n",
    "                Z_gyro=signal.savgol_filter(Z_gyro,5,3)\n",
    "                \n",
    "                #construct window\n",
    "                window=np.array([X_acc[0:25],Y_acc[0:25],Z_acc[0:25],X_gyro[0:25],Y_gyro[0:25],Z_gyro[0:25],\n",
    "                                  X_acc[25:50],Y_acc[25:50],Z_acc[25:50],X_gyro[25:50],Y_gyro[25:50],Z_gyro[25:50],\n",
    "                                  X_acc[50:75],Y_acc[50:75],Z_acc[50:75],X_gyro[50:75],Y_gyro[50:75],Z_gyro[50:75],\n",
    "                                  X_acc[75:100],Y_acc[75:100],Z_acc[75:100],X_gyro[75:100],Y_gyro[75:100],Z_gyro[75:100],\n",
    "                                  X_acc[100:125],Y_acc[100:125],Z_acc[100:125],X_gyro[100:125],Y_gyro[100:125],Z_gyro[100:125],\n",
    "                                  X_acc[125:150],Y_acc[125:150],Z_acc[125:150],X_gyro[125:150],Y_gyro[125:150],Z_gyro[125:150]])\n",
    "                \n",
    "                window2=np.array([[X_acc[0:25],X_acc[25:50],X_acc[50:75],X_acc[75:100],X_acc[100:125],X_acc[125:150]],\n",
    "                    [Y_acc[0:25],Y_acc[25:50],Y_acc[50:75],Y_acc[75:100],Y_acc[100:125],Y_acc[125:150]],\n",
    "                    [Z_acc[0:25],Z_acc[25:50],Z_acc[50:75],Z_acc[75:100],Z_acc[100:125],Z_acc[125:150]],\n",
    "                    [X_gyro[0:25],X_gyro[25:50],X_gyro[50:75],X_gyro[75:100],X_gyro[100:125],X_gyro[125:150]],\n",
    "                    [Y_gyro[0:25],Y_gyro[25:50],Y_gyro[50:75],Y_gyro[75:100],Y_gyro[100:125],Y_gyro[125:150]],\n",
    "                    [Z_gyro[0:25],Z_gyro[25:50],Z_gyro[50:75],Z_gyro[75:100],Z_gyro[100:125],Z_gyro[125:150]]])\n",
    "                \n",
    "                #5 features  what else?2\n",
    "                window_mean=window.mean(axis=-1)\n",
    "                window_stddev=window.std(axis=-1)\n",
    "                window_median=np.median(window,axis=-1)\n",
    "                window_percent25=np.percentile(window,25,axis=-1)\n",
    "                window_percent75=np.percentile(window,75,axis=-1)\n",
    "                \n",
    "                #Drop outliers1 : want to use tnse further\n",
    "                if(labl!=-1):\n",
    "                    xm=window_stddev[[0,6,12,18,24,30]].mean(axis=0)\n",
    "                    ym=window_stddev[[1,7,13,19,25,31]].mean(axis=0)\n",
    "                    zm=window_stddev[[2,8,14,20,26,32]].mean(axis=0)\n",
    "                    #print('total',np.mean([xm,ym,zm]),'labl:', labl)\n",
    "                    action=np.mean([xm,ym,zm])\n",
    "                if(action<0.65):\n",
    "                    label_count[labl]-=1\n",
    "                    break\n",
    "                \n",
    "\n",
    "                #construct window feature\n",
    "                window_feature=np.array([[window_mean],[window_stddev],[window_median],[window_percent25],[window_percent75]])\n",
    "                window_feature=window_feature.reshape(180)\n",
    "                \n",
    "                #construct training and test set\n",
    "                if (label_count[labl]%5!=1):\n",
    "                    training_set.append(window_feature)\n",
    "                    training_label.append(labl)\n",
    "                    traininglabel_count[labl]+=1\n",
    "\n",
    "                else:\n",
    "                    test_set.append(window_feature)\n",
    "                    test_label.append(labl)\n",
    "                    testlabel_count[labl]+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load svm\n",
    "filename='./svm.sav'\n",
    "svm = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# load knn\n",
    "filename='./knn.sav'\n",
    "knn = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# load rf\n",
    "filename='./rf.sav'\n",
    "rf = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# load ETC\n",
    "filename='./ETC.sav'\n",
    "ETC = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8726415094339622\n",
      "[[21  0  0  0  0  0  0  0  0]\n",
      " [ 0 21  4  0  0  0  0  0  0]\n",
      " [ 3  3 40  0  4  0  0  0  0]\n",
      " [ 0  0  0 11  0  0  0  0  0]\n",
      " [ 0  0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  0  8  0  0  0]\n",
      " [ 0  0  0  0  0  0 20  0  0]\n",
      " [ 0  0  0  1  0  4  8 48  0]\n",
      " [ 0  0  0  0  0  0  0  0  8]]\n",
      "[[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "X=training_set\n",
    "y=training_label\n",
    "RF = RandomForestClassifier(200)\n",
    "RF.fit(X, y)\n",
    "test_pred_proba=RF.predict_proba(test_set)\n",
    "\n",
    "#print((test_pred_proba))\n",
    "#for row in test_pred_proba:\n",
    "#    print(np.max([row]))\n",
    "test_pred3=RF.predict(test_set)\n",
    "print(accuracy_score(test_pred3,test_label))\n",
    "print(confusion_matrix(test_pred3, test_label))\n",
    "\n",
    "\n",
    "\n",
    "ohc=OneHotEncoder(categories='auto')\n",
    "onehot_pred3=test_pred3.reshape(-1,1)\n",
    "onehot_pred3=ohc.fit_transform(onehot_pred3).toarray()\n",
    "print(onehot_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12 12 12 12  9  9  9  9 12 12 12 12 10 10 10 10  9  9  9  9 12 12 12 12\n",
      "  7  7  7  7  6  6  6  6  6  6  6  6  0  0  0  0  5  5  5  5  0  0  0  0\n",
      " 12 12 12 12 12 12 12 12  0  0  0  0 12 12 12 12  6  6  6  6 12 12 12 12\n",
      " 12 12 12 12  7  7  7  7  0  0  0  0 12 12 12 12 12 12 12 12  6  6  6  6\n",
      " 12 12 12 12 12 12 12 12 12 12  0  0  5  5  5  5  0  0  0  0  6  6  6  6\n",
      "  0  0  0  0  6  6  6  6 10 10 10 10 13 13 13 13  8  8  8  8  8  8  8  8\n",
      "  0  0  0  0 12 12 12 12 12 12 12 12  5  5  5  5 12 12 12 12  6  6  6  6\n",
      "  5  5  5  5 12 12 12 12  6  6  6  6  6  6  6  6 10 10 10 10 10 10 10 10\n",
      "  5  5  5  5 10 10 10 10  0  0  0  0  0  0  0  0  6  6  6  6]\n",
      "[[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n",
      "0.8301886792452831\n",
      "[ 63   4  72  88  43  34  45  76 132  18   8]\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "#prepare the data\n",
    "X=preprocessing.minmax_scale(training_set)\n",
    "y=training_label\n",
    "#prepare the model\n",
    "SVC = sklearn.svm.SVC(gamma='scale',tol=0.1,probability=True)\n",
    "\n",
    "SVC.fit(X,y)\n",
    "\n",
    "\n",
    "test_pred1=SVC.predict(preprocessing.minmax_scale(test_set))\n",
    "test_pred_proba=SVC.predict_proba(preprocessing.minmax_scale(test_set))\n",
    "\n",
    "ohc=OneHotEncoder(categories='auto')\n",
    "onehot_pred1=test_pred1.reshape(-1,1)\n",
    "onehot_pred1=ohc.fit_transform(onehot_pred1).toarray()\n",
    "print(test_pred1)\n",
    "print(onehot_pred1)\n",
    "#print(confusion_matrix(test_pred1, test_label))\n",
    "\n",
    "print(accuracy_score(test_pred1,test_label))\n",
    "print(SVC.n_support_)\n",
    "#confusion_matrix(test_pred1, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parkj0/anaconda3/envs/venv/lib/python3.7/site-packages/sklearn/preprocessing/data.py:2553: FutureWarning: The default value of `copy` will change from False to True in 0.23 in order to make it more consistent with the default `copy` values of other functions in :mod:`sklearn.preprocessing.data` and prevent unexpected side effects by modifying the value of `X` inplace. To avoid inplace modifications of `X`, it is recommended to explicitly set `copy=True`\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6404494382022472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parkj0/anaconda3/envs/venv/lib/python3.7/site-packages/sklearn/preprocessing/data.py:2553: FutureWarning: The default value of `copy` will change from False to True in 0.23 in order to make it more consistent with the default `copy` values of other functions in :mod:`sklearn.preprocessing.data` and prevent unexpected side effects by modifying the value of `X` inplace. To avoid inplace modifications of `X`, it is recommended to explicitly set `copy=True`\n",
      "  FutureWarning)\n",
      "/home/parkj0/anaconda3/envs/venv/lib/python3.7/site-packages/sklearn/preprocessing/data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (356). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "#window=preprocessing.quantile_transform(window)\n",
    "\n",
    "X=training_set\n",
    "X=preprocessing.quantile_transform(training_set)\n",
    "test_set2=preprocessing.quantile_transform(test_set)\n",
    "y=training_label\n",
    "KNN = NearestCentroid()\n",
    "KNN.fit(X, y)\n",
    "test_pred2=KNN.predict(test_set2)\n",
    "print(accuracy_score(test_pred2,test_label))\n",
    "\n",
    "#onehot_pred2=test_pred2.reshape(-1,1)\n",
    "#onehot_pred2=ohc.fit_transform(onehot_pred2).toarray()\n",
    "#print(onehot_pred2)\n",
    "#confusion_matrix(test_pred2, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356, 13)\n",
      "0.7808988764044944\n",
      "[[36  0  0  4  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  4  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  3 24  8  0  2  0  0  0  0  0  0  0]\n",
      " [ 3  0  5 36  0  4  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0 20  0  0  0  0  4  0  0  4]\n",
      " [ 0  1  3  4  0 18  0  4  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 20  0  0  4  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 48  0  4  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  4  0  0  0  0]\n",
      " [ 4  0  0  0  4  0  7  4  0 44  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  8  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  4  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 12]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "X=training_set\n",
    "y=training_label\n",
    "RF = RandomForestClassifier(200)\n",
    "RF.fit(X, y)\n",
    "test_pred_proba=RF.predict_proba(test_set)\n",
    "print(np.shape(test_pred_proba))\n",
    "#print(np.argmax(x) for x in test_pred_proba)\n",
    "test_pred3=RF.predict(test_set)\n",
    "#for x in test_pred_proba:\n",
    "#    print(x)\n",
    "print(accuracy_score(test_pred3,test_label))\n",
    "print(confusion_matrix(test_pred3, test_label))\n",
    "#onehot_pred3=test_pred2.reshape(-1,1)\n",
    "#onehot_pred3=ohc.fit_transform(onehot_pred3).toarray()\n",
    "#print(onehot_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356,)\n"
     ]
    }
   ],
   "source": [
    "array=np.array(test_pred_proba)\n",
    "newpred2=np.zeros(len(test_pred3))\n",
    "for x in range(len(test_pred_proba)):\n",
    "    if(np.max(test_pred_proba[x])>0.3):\n",
    "        newpred2[x]=test_pred3[x]\n",
    "    else:\n",
    "        newpred2[x]=-1\n",
    "        i=0\n",
    "        #print(np.shape(np.argmax(test_pred_proba[x])))\n",
    "print(np.shape(newpred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7331460674157303\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(newpred2,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble 1 : unanimous consensus\n",
    "#ensemble1_pred= onehot_pred1*onehot_pred2*onehot_pred3\n",
    "#print(ensemble1_pred)\n",
    "#ensemble1_pred=np.argmax(ensemble1_pred,axis=1)\n",
    "#print(ensemble1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble 2 : majority consensus\n",
    "#ensemble2_pred= (onehot_pred1+onehot_pred2+onehot_pred3)/2\n",
    "#ensemble2_pred= ensemble2_pred.astype('int64') \n",
    "#ensemble2_pred= ensemble2_pred.astype('float64') \n",
    "#ensemble2_pred=np.argmax(ensemble2_pred,axis=1)\n",
    "#print(ensemble2_pred)\n",
    "#print(test_label)\n",
    "#print(accuracy_score(ensemble2_pred,test_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ETC.joblib']"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the model\n",
    "\n",
    "from joblib import dump, load\n",
    "filename='./svm.sav'\n",
    "pickle.dump(SVC,open(filename,'wb'))\n",
    "\n",
    "filename='./knn.sav'\n",
    "pickle.dump(KNN,open(filename,'wb'))\n",
    "dump(KNN,'knn.joblib')\n",
    "\n",
    "filename='./rf.sav'\n",
    "pickle.dump(RF,open(filename,'wb'))\n",
    "dump(RF,'rf.joblib')\n",
    "\n",
    "filename='./ETC.sav'\n",
    "pickle.dump(ETC,open(filename,'wb'))\n",
    "dump(ETC,'ETC.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7865168539325843\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "bagging = BaggingClassifier(KNeighborsClassifier(),max_samples=0.5, max_features=0.5)\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X=training_set\n",
    "y=training_label\n",
    "\n",
    "ETC=ExtraTreesClassifier(150)\n",
    "DTC=DecisionTreeClassifier()\n",
    "\n",
    "ETC.fit(X,y)\n",
    "DTC.fit(X,y)\n",
    "test_pred4=ETC.predict(test_set)\n",
    "test_pred5=DTC.predict(test_set)\n",
    "print(accuracy_score(test_pred4,test_label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356,)\n",
      "[12. 12. 12. 12.  9.  9.  9.  9.  7.  7.  7.  7. 10. 10. 10. 10. 12. 12.\n",
      " 12. 12. 10. 10. 10. 10.  7.  7.  7.  7.  6.  6.  6.  6.  6.  6.  6.  6.\n",
      "  0.  0.  0.  0.  5.  5.  5.  5.  6.  6.  6.  6. 10. 10. 10. 10. 12. 12.\n",
      " 12. 12.  0.  0.  0.  0. 10. 10. 12. 10.  6.  6.  6.  6. 12. 12. 12. 12.\n",
      " 10. 10. 10. 10.  7.  7.  7.  7.  0.  0.  0.  0. 12. 12. 12. 12. 12. 12.\n",
      " 12. 12.  6.  6.  6.  6. 12. 12. 12. 12. 12. 12. 12. 12.  7.  7.  6.  7.\n",
      "  5.  5.  5.  5.  0.  0.  0.  0.  6.  6.  6.  6.  0.  0.  0.  0.  5.  5.\n",
      "  5.  5. 10. 10. 10. 10. 13. 13. 13. 13.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      " 13. 13. 13. 13. 12. 12. 12. 12. 12. 12. 12. 12.  5.  5.  5.  5. 12. 12.\n",
      " 12. 12.  5.  5.  5.  5.  5.  5.  5.  5. 12. 12. 12. 12.  5.  5.  5.  5.\n",
      "  6.  6.  6.  6.  8.  6.  6.  8.  8.  8.  8.  8. 12. 12. 12. 12. 10. 10.\n",
      " -1. -1.  5.  5.  5.  5.  0. 12. 12.  0.  5.  5.  5.  5.  7.  7.  7.  7.\n",
      "  8.  8.  8.  8.  0.  0.  0.  0. -1. -1. -1. -1.  0.  0.  0.  0.  6.  6.\n",
      "  6.  6.  0.  0.  0.  0.  7.  7.  7.  7.  0.  0.  0.  0.  7.  7.  7.  7.\n",
      " 15. 15. 15. 15. 15. 15. 15. 15. 14. 14. 14. 14. 15. 15. 15. 15.  5.  5.\n",
      "  5.  5.  0.  0.  0.  0.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.\n",
      " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
      " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  6.  6.  6.  6.\n",
      "  6.  6.  6.  6. 10. 10. 10. 10. 10. 10. 10. 10.  6.  5.  6.  6. 12. 12.\n",
      " 12. 12.  0.  0.  0.  0.  6.  6.  6.  6.  6.  6.  6.  6.]\n",
      "0.7752808988764045\n"
     ]
    }
   ],
   "source": [
    "test_pred_proba2=ETC.predict_proba(test_set)\n",
    "array=np.array(test_pred_proba2)\n",
    "newpred3=np.zeros(len(test_pred4))\n",
    "for x in range(len(test_pred_proba2)):\n",
    "    if(np.max(test_pred_proba2[x])>0.2):\n",
    "        newpred3[x]=test_pred4[x]\n",
    "    else:\n",
    "        newpred3[x]=-1\n",
    "        i=0\n",
    "        #print(np.shape(np.argmax(test_pred_proba[x])))\n",
    "print(np.shape(newpred3))\n",
    "print(newpred3)\n",
    "print(accuracy_score(newpred3,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (13,13) (17,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-277-4719162e6dbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0maccuracy_per_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maccuracy_per_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pred4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtestlabel_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0maccuracy_per_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagonal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maccuracy_per_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pred5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtestlabel_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (13,13) (17,) "
     ]
    }
   ],
   "source": [
    "accuracy_per_label=[]\n",
    "\n",
    "accuracy_per_label=confusion_matrix(test_pred4, test_label)/testlabel_count\n",
    "accuracy_per_label.diagonal()\n",
    "accuracy_per_label=confusion_matrix(test_pred5, test_label)/testlabel_count\n",
    "accuracy_per_label.diagonal()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pred1\n",
    "array([0.65909091, 0.83333333, 0.        , 0.8       , 0.08333333,\n",
    "       0.59375   , 0.8       , 0.625     , 0.5       , 0.71428571,\n",
    "       0.91666667, 0.        , 0.76666667, 0.66666667, 0.66666667,\n",
    "       1.        ])\n",
    "       \n",
    "pred2\n",
    "array([0.61363636, 0.66666667, 0.        , 0.4       , 0.        ,\n",
    "       0.4375    , 0.8       , 0.83333333, 0.5       , 0.57142857,\n",
    "       0.60416667, 0.        , 0.58333333, 0.66666667, 1.        ,\n",
    "       1.        ])\n",
    "\n",
    "pred3\n",
    "array([0.90909091, 1.        , 0.        , 1.        , 0.66666667,\n",
    "       0.625     , 0.9       , 0.83333333, 0.66666667, 0.71428571,\n",
    "       1.        , 0.        , 0.73333333, 0.66666667, 1.        ,\n",
    "       0.75      ])\n",
    "pred4\n",
    "array([0.90909091, 1.        , 0.        , 0.8       , 0.66666667,\n",
    "       0.71875   , 0.9       , 0.83333333, 0.54166667, 0.85714286,\n",
    "       1.        , 0.        , 0.78333333, 0.66666667, 1.        ,\n",
    "       0.75      ])\n",
    "\n",
    "pred5\n",
    "array([0.72727273, 0.75      , 0.5       , 0.6       , 0.33333333,\n",
    "       0.5       , 0.625     , 0.83333333, 0.33333333, 0.67857143,\n",
    "       0.91666667, 0.        , 0.73333333, 0.33333333, 0.        ,\n",
    "       1.        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=[2,11,8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
