{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##complex data와 똑같이 40ms로 parsing했음 데이터 4배라고 생각하고 뻥튀기시켜봄 정확도는 10ms와 비슷하게 나옴\n",
    "\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#filename queue\n",
    "filename_queue=glob.glob('./rawdata/data[1-6].csv')\n",
    "#Create return path\n",
    "return_path='./rawdata/data.csv'\n",
    "create_file=open(return_path,'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "123\n",
      "1\n",
      "123\n",
      "1\n",
      "123\n",
      "1\n",
      "123\n",
      "1\n",
      "123\n",
      "1\n",
      "123\n"
     ]
    }
   ],
   "source": [
    "#Parsing data\n",
    "\n",
    "training_set=[]\n",
    "test_set=[]\n",
    "training_label=[]\n",
    "test_label=[]\n",
    "index=[]\n",
    "label_count=np.zeros(17-len(index))\n",
    "traininglabel_count=np.zeros(17-len(index))\n",
    "testlabel_count=np.zeros(17-len(index))\n",
    "\n",
    "df=pd.DataFrame({\"labl\":[-1],\"total\":[0.11111]})\n",
    "\n",
    "\n",
    "#return_file=open(return_path,'a')\n",
    "#writer=csv.writer(return_file)\n",
    "#writer.writerow()\n",
    "n_data=[]\n",
    "\n",
    "for filename in filename_queue:\n",
    "    print(1)\n",
    "    file=open(filename, newline='')\n",
    "    reader=csv.reader(file)\n",
    "    header=next(reader)\n",
    "    \n",
    "    for row in reader:\n",
    "        row[4:]=[float(i) for i in row[4:]]\n",
    "        date=datetime.strptime(row[0],'%Y/%m/%d')\n",
    "        msec=row[1:3]\n",
    "        if(int(row[3])==0):\n",
    "            labl=0\n",
    "            label_count[labl]+=1\n",
    "        if(int(row[3])==1):\n",
    "            labl=1\n",
    "            label_count[labl]+=1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        if labl not in index:\n",
    "            for x in range(4):\n",
    "                X_acc=list(row[4*i+4+x] for i in range(150))\n",
    "                Y_acc=list(row[4*i+604+x] for i in range(150))\n",
    "                Z_acc=list(row[4*i+1204+x] for i in range(150))\n",
    "                X_gyro=list(row[4*i+1804+x] for i in range(150))\n",
    "                Y_gyro=list(row[4*i+2404+x] for i in range(150))\n",
    "                Z_gyro=list(row[4*i+3004+x] for i in range(150))\n",
    "\n",
    "                #window=np.array([[X_acc[0:25],X_acc[25:50],X_acc[50:75],X_acc[75:100],X_acc[100:125],X_acc[125:150]],\n",
    "                #    [Y_acc[0:25],Y_acc[25:50],Y_acc[50:75],Y_acc[75:100],Y_acc[100:125],Y_acc[125:150]],\n",
    "                #    [Z_acc[0:25],Z_acc[25:50],Z_acc[50:75],Z_acc[75:100],Z_acc[100:125],Z_acc[125:150]],\n",
    "                #    [X_gyro[0:25],X_gyro[25:50],X_gyro[50:75],X_gyro[75:100],X_gyro[100:125],X_gyro[125:150]],\n",
    "                #    [Y_gyro[0:25],Y_gyro[25:50],Y_gyro[50:75],Y_gyro[75:100],Y_gyro[100:125],Y_gyro[125:150]],\n",
    "                #    [Z_gyro[0:25],Z_gyro[25:50],Z_gyro[50:75],Z_gyro[75:100],Z_gyro[100:125],Z_gyro[125:150]]])\n",
    "                \n",
    "                window=np.array([X_acc[0:25],Y_acc[0:25],Z_acc[0:25],X_gyro[0:25],Y_gyro[0:25],Z_gyro[0:25],\n",
    "                                  X_acc[25:50],Y_acc[25:50],Z_acc[25:50],X_gyro[25:50],Y_gyro[25:50],Z_gyro[25:50],\n",
    "                                  X_acc[50:75],Y_acc[50:75],Z_acc[50:75],X_gyro[50:75],Y_gyro[50:75],Z_gyro[50:75],\n",
    "                                  X_acc[75:100],Y_acc[75:100],Z_acc[75:100],X_gyro[75:100],Y_gyro[75:100],Z_gyro[75:100],\n",
    "                                  X_acc[100:125],Y_acc[100:125],Z_acc[100:125],X_gyro[100:125],Y_gyro[100:125],Z_gyro[100:125],\n",
    "                                  X_acc[125:150],Y_acc[125:150],Z_acc[125:150],X_gyro[125:150],Y_gyro[125:150],Z_gyro[125:150]])\n",
    "                \n",
    "                \n",
    "                                \n",
    "                window_mean=window.mean(axis=-1)\n",
    "                window_stddev=window.std(axis=-1)\n",
    "                \n",
    "                #print('x:',window_stddev[[0,6,12,18,24,30]].mean(axis=0),labl)\n",
    "                xm=window_stddev[[0,6,12,18,24,30]].mean(axis=0)\n",
    "                #print('y:',window_stddev[[1,7,13,19,25,31]].mean(axis=0),labl)\n",
    "                ym=window_stddev[[1,7,13,19,25,31]].mean(axis=0)\n",
    "                #print('z:',window_stddev[[2,8,14,20,26,32]].mean(axis=0),labl)\n",
    "                zm=window_stddev[[2,8,14,20,26,32]].mean(axis=0)\n",
    "                #print('total',np.mean([xm,ym,zm]),'labl:', labl)\n",
    "                #sort.append([])\n",
    "                action=np.array([xm,ym])\n",
    "                print(1)\n",
    "                #df2= pd.DataFrame({\"labl\":[labl],\"total\":[np.mean([xm,ym,zm])]})\n",
    "                #df=df.append(df2)\n",
    "                #5 features  what else?2\n",
    "                \n",
    "                \n",
    "                #label_count[labl]+=1\n",
    "\n",
    "                df.sort_values('total')\n",
    "                window_median=np.median(window,axis=-1)\n",
    "                window_percent25=np.percentile(window,25,axis=-1)\n",
    "                window_percent75=np.percentile(window,75,axis=-1)\n",
    "\n",
    "                window_feature=np.array([[window_mean],[window_stddev],[window_median],[window_percent25],[window_percent75]])\n",
    "                window_feature=window_feature.reshape(180)\n",
    "\n",
    "                if (label_count[labl]%5!=1):\n",
    "                    training_set.append(action)\n",
    "                    training_label.append(labl)\n",
    "                    traininglabel_count[labl]+=1\n",
    "                else:\n",
    "                    test_set.append(action)\n",
    "                    test_label.append(labl)\n",
    "                    testlabel_count[labl]+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parkj0/anaconda3/envs/venv/lib/python3.7/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "/home/parkj0/anaconda3/envs/venv/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8f1c4e7d2a5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mclf_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'KNN'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# get the prediction label and outlier scores of the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.7/site-packages/pyod/models/knn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# validate inputs X and y (optional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_n_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from pyod.models.knn import KNN   # kNN detector\n",
    "from pyod.utils.data import evaluate_print\n",
    "from pyod.utils.data import generate_data\n",
    "\n",
    "X_train=training_set\n",
    "y_train=training_label\n",
    "X_test=test_set\n",
    "y_test=test_label\n",
    "# train kNN detector\n",
    "clf_name = 'KNN'\n",
    "clf = KNN()\n",
    "clf.fit(X_train)\n",
    "\n",
    "# get the prediction label and outlier scores of the training data\n",
    "y_train_pred = clf.labels_  # binary labels (0: inliers, 1: outliers)\n",
    "y_train_scores = clf.decision_scores_  # raw outlier scores\n",
    "\n",
    "# get the prediction on the test data\n",
    "y_test_pred = clf.predict(X_test)  # outlier labels (0 or 1)\n",
    "y_test_scores = clf.decision_function(X_test)  # outlier scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "On Training Data:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_train_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-408785edf71e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# evaluate and print the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nOn Training Data:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mevaluate_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nOn Test Data:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mevaluate_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train_scores' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# evaluate and print the results\n",
    "print(\"\\nOn Training Data:\")\n",
    "evaluate_print(clf_name, y_train, y_train_scores)\n",
    "print(\"\\nOn Test Data:\")\n",
    "evaluate_print(clf_name, y_test, y_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c16e72429b72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexample\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m visualize(clf_name, X_train, y_train, X_test, y_test, y_train_pred,\n\u001b[0m\u001b[1;32m      4\u001b[0m     y_test_pred, show_figure=True, save_figure=False)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train_pred' is not defined"
     ]
    }
   ],
   "source": [
    "from pyod.utils.example import visualize\n",
    "\n",
    "visualize(clf_name, X_train, y_train, X_test, y_test, y_train_pred,\n",
    "    y_test_pred, show_figure=True, save_figure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parkj0/anaconda3/envs/venv/lib/python3.7/site-packages/numpy/lib/function_base.py:392: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/parkj0/anaconda3/envs/venv/lib/python3.7/site-packages/numpy/core/_methods.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "/home/parkj0/anaconda3/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:35: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "/home/parkj0/anaconda3/envs/venv/lib/python3.7/site-packages/numpy/lib/function_base.py:2451: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/parkj0/anaconda3/envs/venv/lib/python3.7/site-packages/numpy/lib/function_base.py:2451: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8dc217420ccf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     clf = KNN(algorithm='auto', metric='mahalanobis',\n\u001b[1;32m     37\u001b[0m               metric_params={'V': X_train_cov})\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# get the prediction labels and outlier scores of the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.7/site-packages/pyod/models/knn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# validate inputs X and y (optional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_n_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Example of using kNN with mahalanobis distance for outlier detection\n",
    "\"\"\"\n",
    "# Author: Yue Zhao <zhaoy@cmu.edu>\n",
    "# License: BSD 2 clause\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# temporary solution for relative imports in case pyod is not installed\n",
    "# if pyod is installed, no need to use the following line\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..')))\n",
    "\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.utils.data import generate_data\n",
    "from pyod.utils.data import evaluate_print\n",
    "from pyod.utils.example import visualize\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    contamination = 0.1  # percentage of outliers\n",
    "    n_train = 200  # number of training points\n",
    "    n_test = 100  # number of testing points\n",
    "\n",
    "    # Generate sample data\n",
    "\n",
    "    # train kNN detector with mahalanobis distance\n",
    "    clf_name = 'KNN (mahalanobis distance)'\n",
    "    # calculate covariance for mahalanobis distance\n",
    "    X_train_cov = np.cov(X_train, rowvar=False)\n",
    "    clf = KNN(algorithm='auto', metric='mahalanobis',\n",
    "              metric_params={'V': X_train_cov})\n",
    "    clf.fit(X_train)\n",
    "\n",
    "    # get the prediction labels and outlier scores of the training data\n",
    "    y_train_pred = clf.labels_  # binary labels (0: inliers, 1: outliers)\n",
    "    y_train_scores = clf.decision_scores_  # raw outlier scores\n",
    "\n",
    "    # get the prediction on the test data\n",
    "    y_test_pred = clf.predict(X_test)  # outlier labels (0 or 1)\n",
    "    y_test_scores = clf.decision_function(X_test)  # outlier scores\n",
    "\n",
    "    # evaluate and print the results\n",
    "    print(\"\\nOn Training Data:\")\n",
    "    evaluate_print(clf_name, y_train, y_train_scores)\n",
    "    print(\"\\nOn Test Data:\")\n",
    "    evaluate_print(clf_name, y_test, y_test_scores)\n",
    "\n",
    "    # visualize the results\n",
    "    visualize(clf_name, X_train, y_train, X_test, y_test, y_train_pred,\n",
    "              y_test_pred, show_figure=True, save_figure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
