{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "##complex data와 똑같이 40ms로 parsing했음 데이터 4배라고 생각하고 뻥튀기시켜봄 정확도는 10ms와 비슷하게 나옴\n",
    "\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "#filename queue\n",
    "filename_queue=glob.glob('./rawdata/data[1-5].csv')\n",
    "#Create return path\n",
    "return_path='./rawdata/data.csv'\n",
    "create_file=open(return_path,'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parsing data\n",
    "\n",
    "training_set=[]\n",
    "test_set=[]\n",
    "training_label=[]\n",
    "test_label=[]\n",
    "index=[]\n",
    "label_count=np.zeros(16)\n",
    "traininglabel_count=np.zeros(16)\n",
    "testlabel_count=np.zeros(16)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#return_file=open(return_path,'a')\n",
    "#writer=csv.writer(return_file)\n",
    "#writer.writerow()\n",
    "n_data=[]\n",
    "\n",
    "for filename in filename_queue:\n",
    "    file=open(filename, newline='')\n",
    "    \n",
    "    reader=csv.reader(file)\n",
    "    header=next(reader)\n",
    "    \n",
    "    for row in reader:\n",
    "        row[4:]=[float(i) for i in row[4:]]\n",
    "        date=datetime.strptime(row[0],'%Y/%m/%d')\n",
    "        msec=row[1:3]\n",
    "        labl=int(row[3])\n",
    "        if labl not in index:\n",
    "            label_count[labl]+=1\n",
    "            for x in range(4):\n",
    "                X_acc=list(row[4*i+4+x] for i in range(150))\n",
    "                Y_acc=list(row[4*i+604+x] for i in range(150))\n",
    "                Z_acc=list(row[4*i+1204+x] for i in range(150))\n",
    "                X_gyro=list(row[4*i+1804+x] for i in range(150))\n",
    "                Y_gyro=list(row[4*i+2404+x] for i in range(150))\n",
    "                Z_gyro=list(row[4*i+3004+x] for i in range(150))\n",
    "\n",
    "                window=np.array([[X_acc[0:25],X_acc[25:50],X_acc[50:75],X_acc[75:100],X_acc[100:125],X_acc[125:150]],\n",
    "                    [Y_acc[0:25],Y_acc[25:50],Y_acc[50:75],Y_acc[75:100],Y_acc[100:125],Y_acc[125:150]],\n",
    "                    [Z_acc[0:25],Z_acc[25:50],Z_acc[50:75],Z_acc[75:100],Z_acc[100:125],Z_acc[125:150]],\n",
    "                    [X_gyro[0:25],X_gyro[25:50],X_gyro[50:75],X_gyro[75:100],X_gyro[100:125],X_gyro[125:150]],\n",
    "                    [Y_gyro[0:25],Y_gyro[25:50],Y_gyro[50:75],Y_gyro[75:100],Y_gyro[100:125],Y_gyro[125:150]],\n",
    "                    [Z_gyro[0:25],Z_gyro[25:50],Z_gyro[50:75],Z_gyro[75:100],Z_gyro[100:125],Z_gyro[125:150]]])\n",
    "\n",
    "                window=np.array([[X_acc[0:25],Y_acc[0:25],Z_acc[0:25],X_gyro[0:25],Y_gyro[0:25],Z_gyro[0:25]],\n",
    "                                  [X_acc[25:50],Y_acc[25:50],Z_acc[25:50],X_gyro[25:50],Y_gyro[25:50],Z_gyro[25:50]],\n",
    "                                  [X_acc[50:75],Y_acc[50:75],Z_acc[50:75],X_gyro[50:75],Y_gyro[50:75],Z_gyro[50:75]],\n",
    "                                  [X_acc[75:100],Y_acc[75:100],Z_acc[75:100],X_gyro[75:100],Y_gyro[75:100],Z_gyro[75:100]],\n",
    "                                  [X_acc[100:125],Y_acc[100:125],Z_acc[100:125],X_gyro[100:125],Y_gyro[100:125],Z_gyro[100:125]],\n",
    "                                  [X_acc[125:150],Y_acc[125:150],Z_acc[125:150],X_gyro[125:150],Y_gyro[125:150],Z_gyro[125:150]]])\n",
    "\n",
    "                #5 features  what else?2\n",
    "                window_mean=window.mean(axis=-1)\n",
    "                window_stddev=window.std(axis=-1)\n",
    "                window_median=np.median(window,axis=-1)\n",
    "                window_percent25=np.percentile(window,25,axis=-1)\n",
    "                window_percent75=np.percentile(window,75,axis=-1)\n",
    "\n",
    "                window_feature=np.array([[window_mean],[window_stddev],[window_median],[window_percent25],[window_percent75]])\n",
    "                window_feature=window_feature.reshape(180)\n",
    "\n",
    "                if (label_count[labl]%5!=1):\n",
    "                    training_set.append(window_feature)\n",
    "                    training_label.append(labl)\n",
    "                    traininglabel_count[labl]+=1\n",
    "\n",
    "                else:\n",
    "                    test_set.append(window_feature)\n",
    "                    test_label.append(labl)\n",
    "                    testlabel_count[labl]+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1528\n",
      "408\n"
     ]
    }
   ],
   "source": [
    "#print(window_feature.shape)\n",
    "print(len(training_label))\n",
    "print(len(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7009803921568627\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "#prepare the data\n",
    "X=training_set\n",
    "y=training_label\n",
    "#prepare the model\n",
    "SVC = sklearn.svm.SVC(gamma='scale',tol=0.1,probability=True)\n",
    "\n",
    "SVC.fit(X,y)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "test_pred1=SVC.predict(test_set)\n",
    "test_pred_proba=SVC.predict_proba(test_set)\n",
    "\n",
    "ohc=OneHotEncoder(categories=[range(16)])\n",
    "onehot_pred1=test_pred1.reshape(-1,1)\n",
    "onehot_pred1=ohc.fit_transform(onehot_pred1).toarray()\n",
    "#print(test_pred1)\n",
    "#print(onehot_pred1)\n",
    "\n",
    "print(accuracy_score(test_pred1,test_label))\n",
    "#print(SVC.n_support_)\n",
    "#confusion_matrix(test_pred1, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6004901960784313\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "KNN = NearestCentroid()\n",
    "KNN.fit(X, y)\n",
    "test_pred2=KNN.predict(test_set)\n",
    "print(accuracy_score(test_pred2,test_label))\n",
    "\n",
    "onehot_pred2=test_pred2.reshape(-1,1)\n",
    "onehot_pred2=ohc.fit_transform(onehot_pred2).toarray()\n",
    "#print(onehot_pred2)\n",
    "#confusion_matrix(test_pred2, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408, 16)\n",
      "0.8112745098039216\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "RF = RandomForestClassifier(200)\n",
    "RF.fit(X, y)\n",
    "test_pred_proba=RF.predict_proba(test_set)\n",
    "print(np.shape(test_pred_proba))\n",
    "#print(np.argmax(x) for x in test_pred_proba)\n",
    "test_pred3=RF.predict(test_set)\n",
    "#for x in test_pred_proba:\n",
    "#    print(x)\n",
    "print(accuracy_score(test_pred3,test_label))\n",
    "#print(confusion_matrix(test_pred3, test_label))\n",
    "onehot_pred3=test_pred2.reshape(-1,1)\n",
    "onehot_pred3=ohc.fit_transform(onehot_pred3).toarray()\n",
    "#print(onehot_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7  7  7  7  9  9  9  9 10 10 10 10 10 10 10 10  9  9  9  9 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10  9  9  9  9  6  6  6  6  7  7  7  7  1  1  1  1\n",
      "  6  6  6  6 14 14 14 14  0  0  0  0  0  0  0  0  6  6  6  6  5  5  5  5\n",
      "  7  7  7  7  3  3  3  3 12 12 12 12  6  6  6  6 12 12 12 12  1  1  1  1\n",
      " 12 10 12 12 12 12 12 12 12 12 12 12  6  6  6  6 12  9  9 12 12 12 12 12\n",
      "  6  6  6  6  5  5  5  5  0  0  0  0 12 12 12 12 12 12 12 12  6  6  6  6\n",
      " 12 12 12 12  0  0  0  0  5  5  5  5  0  0  0  0  3  3  3  3 12 12 12 12\n",
      "  6  6  6  6  1  1  1  1  0  0  0  0  1  1  1  1 10 10 10 10 12 12 12 12\n",
      " 13 13 13 13  8  8  8  8 14 14 14 14  8  8  8  8 14 14 14 14 13 13 13 13\n",
      "  0  0  0  0 12 12 12 12  5  5  5  5  6  6  6  6  6  6  6  6 12 12 12 12\n",
      "  1  1  1  1  5  5  5  5  6  6  6  6  3  3  3  3  7  7  7  7  8  8  8  8\n",
      " 12 12 12 12  1  1  1  1  8  8  8  8  1  1  1  1  8  8  8  8  0  0  0  0\n",
      "  4  4  4  4  8  8  8  8  4  4  4  4  7  7  7  7  4  4  4  4 10 10  3  3\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  7  7  7  7  3  3  3  3 15 15 15 15\n",
      " 15 15 15 15 14 14 14 14 15 15 15 15  0  0  0  0  4  4  4  4  0  0  0  0\n",
      " 12 12 12 12  9  9  9  9  9  9  9  9 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  6  6  6  6 12 12 12 12]\n",
      "(408,)\n"
     ]
    }
   ],
   "source": [
    "print(test_pred3)\n",
    "np.shape(test_pred3)\n",
    "newpred2=np.zeros(len(test_pred3))\n",
    "print(np.shape(newpred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 12, 12, 12, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 9, 9, 9, 9, 12, 12, 12, 12, 10, 10, 10, 10, 10, 10, 10, 10, 9, 9, 9, 9, 6, 6, 6, 6, 7, 7, 7, 7, 1, 1, 1, 1, 6, 6, 6, 6, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 6, 6, 6, 6, 5, 5, 5, 5, 7, 7, 7, 7, 3, 3, 3, 3, 4, 4, 4, 4, 6, 6, 6, 6, 12, 12, 12, 12, 1, 1, 1, 1, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 0, 0, 0, 0, 9, 9, 9, 9, 12, 12, 12, 12, 6, 6, 6, 6, 5, 5, 5, 5, 0, 0, 0, 0, 12, 12, 12, 12, 12, 12, 12, 12, 6, 6, 6, 6, 7, 7, 7, 7, 2, 2, 2, 2, 5, 5, 5, 5, 0, 0, 0, 0, 3, 3, 3, 3, 12, 12, 12, 12, 6, 6, 6, 6, 1, 1, 1, 1, 5, 5, 5, 5, 1, 1, 1, 1, 10, 10, 10, 10, 13, 13, 13, 13, 13, 13, 13, 13, 8, 8, 8, 8, 14, 14, 14, 14, 8, 8, 8, 8, 14, 14, 14, 14, 13, 13, 13, 13, 0, 0, 0, 0, 12, 12, 12, 12, 5, 5, 5, 5, 8, 8, 8, 8, 6, 6, 6, 6, 12, 12, 12, 12, 1, 1, 1, 1, 5, 5, 5, 5, 8, 8, 8, 8, 3, 3, 3, 3, 7, 7, 7, 7, 5, 5, 5, 5, 12, 12, 12, 12, 11, 11, 11, 11, 6, 6, 6, 6, 1, 1, 1, 1, 8, 8, 8, 8, 12, 12, 12, 12, 5, 5, 5, 5, 8, 8, 8, 8, 15, 15, 15, 15, 7, 7, 7, 7, 4, 4, 4, 4, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 3, 3, 3, 3, 15, 15, 15, 15, 15, 15, 15, 15, 14, 14, 14, 14, 15, 15, 15, 15, 0, 0, 0, 0, 4, 4, 4, 4, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 6, 6, 6, 6, 12, 12, 12, 12]\n"
     ]
    }
   ],
   "source": [
    "print(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408,)\n"
     ]
    }
   ],
   "source": [
    "array=np.array(test_pred_proba)\n",
    "newpred2=np.zeros(len(test_pred3))\n",
    "for x in range(len(test_pred_proba)):\n",
    "    if(np.max(test_pred_proba[x])>0.3):\n",
    "        newpred2[x]=test_pred3[x]\n",
    "    else:\n",
    "        newpred2[x]=-1\n",
    "        i=0\n",
    "        #print(np.shape(np.argmax(test_pred_proba[x])))\n",
    "print(np.shape(newpred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7549019607843137\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(newpred2,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble 1 : unanimous consensus\n",
    "ensemble1_pred= onehot_pred1*onehot_pred2*onehot_pred3\n",
    "#print(ensemble1_pred)\n",
    "ensemble1_pred=np.argmax(ensemble1_pred,axis=1)\n",
    "#print(ensemble1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6004901960784313\n"
     ]
    }
   ],
   "source": [
    "#ensemble 2 : majority consensus\n",
    "ensemble2_pred= (onehot_pred1+onehot_pred2+onehot_pred3)/2\n",
    "ensemble2_pred= ensemble2_pred.astype('int64') \n",
    "ensemble2_pred= ensemble2_pred.astype('float64') \n",
    "ensemble2_pred=np.argmax(ensemble2_pred,axis=1)\n",
    "#print(ensemble2_pred)\n",
    "#print(test_label)\n",
    "print(accuracy_score(ensemble2_pred,test_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf.joblib']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the model\n",
    "\n",
    "from joblib import dump, load\n",
    "filename='./svm.sav'\n",
    "pickle.dump(SVC,open(filename,'wb'))\n",
    "\n",
    "filename='./knn.sav'\n",
    "pickle.dump(KNN,open(filename,'wb'))\n",
    "dump(KNN,'knn.joblib')\n",
    "\n",
    "filename='./rf.sav'\n",
    "pickle.dump(RF,open(filename,'wb'))\n",
    "dump(RF,'rf.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8112745098039216\n",
      "0.6127450980392157\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "bagging = BaggingClassifier(KNeighborsClassifier(),max_samples=0.5, max_features=0.5)\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ETC=ExtraTreesClassifier(300)\n",
    "DTC=DecisionTreeClassifier()\n",
    "\n",
    "ETC.fit(X,y)\n",
    "DTC.fit(X,y)\n",
    "test_pred4=ETC.predict(test_set)\n",
    "test_pred5=DTC.predict(test_set)\n",
    "print(accuracy_score(test_pred4,test_label))\n",
    "print(accuracy_score(test_pred5,test_label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408,)\n",
      "[ 7.  7.  7.  7.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.  9.  9.\n",
      "  9.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.  9.  9.  9.\n",
      "  6.  6.  6.  6.  7.  7.  7.  7.  1.  1.  1.  1.  6.  6.  6.  6. 14. 14.\n",
      " 14. 12.  0.  0.  0.  0.  0.  0.  0.  0.  6.  6.  6.  6.  5.  5.  5.  5.\n",
      "  7.  7.  7.  7.  9.  9. 10.  3. -1. -1. -1. -1.  6.  6.  6.  6. 12. 12.\n",
      " 12. 12.  1.  1.  1.  1. 10. 10. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12.\n",
      "  6. -1.  6. -1. 12. 12. 12. 12. 12. 12. 12. 12.  6.  6.  6.  6.  5.  5.\n",
      "  5.  5.  0.  0.  0.  0. 12. 12. 12. 12. 12. 12. 12. 12.  6.  6.  6.  6.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  5.  5.  5.  5.  0.  0.  0.  0.  3.  3.\n",
      "  3.  3. 12. 12. 12. 12.  6.  6.  6.  6.  1.  1.  1.  1.  0.  0.  0.  0.\n",
      "  1.  1.  1.  1. 10. 10. 10. 10. 12. 12. 12. 12. 13. 13. 13. 13.  8.  8.\n",
      "  8.  8. 14. 14. 14. 14.  8.  8.  8.  8. 14. 14. 14. 14. 13. 13. 13. 13.\n",
      "  0.  0.  0.  0. 12. 12. 12. 12.  5.  5.  5.  5.  6.  6.  6.  6.  6.  6.\n",
      "  6.  6. 12. 12. 12. 12.  1.  1.  1.  1.  5.  5.  5.  5.  6.  6.  6.  6.\n",
      "  3.  3.  3.  3.  7.  7.  7.  7. 10. 10. 10. 10. 12. 12. 12. 12. 14. 14.\n",
      " 14. 14.  8.  8.  8.  8.  1.  1.  1.  1.  8.  8.  8.  8.  0.  0.  0.  0.\n",
      "  5. -1. -1. -1.  8.  8.  8.  8.  4.  4.  4.  4.  7.  7.  7.  7.  4.  4.\n",
      "  4.  4.  3.  3.  3.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  7.  7.  7.  7.  3.  3.  3.  3. 15. 15. 15. 15. 15. 15. 15. 15. 14. 14.\n",
      " 14. 14. 15. 15. 15. 15.  0.  0.  0.  0.  4.  4.  4.  4.  0.  0.  0.  0.\n",
      " 12. 12. 12. 12.  9.  9.  9.  9.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10.\n",
      " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
      " 10. 10. 10. 10.  6.  6.  6.  6. 12. 12. 12. 12.]\n",
      "0.803921568627451\n"
     ]
    }
   ],
   "source": [
    "test_pred_proba2=ETC.predict_proba(test_set)\n",
    "array=np.array(test_pred_proba2)\n",
    "newpred3=np.zeros(len(test_pred4))\n",
    "for x in range(len(test_pred_proba2)):\n",
    "    if(np.max(test_pred_proba2[x])>0.2):\n",
    "        newpred3[x]=test_pred4[x]\n",
    "    else:\n",
    "        newpred3[x]=-1\n",
    "        i=0\n",
    "        #print(np.shape(np.argmax(test_pred_proba[x])))\n",
    "print(np.shape(newpred3))\n",
    "print(newpred3)\n",
    "print(accuracy_score(newpred3,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81818182, 0.75      , 0.5       , 0.6       , 0.33333333,\n",
       "       0.5       , 0.525     , 0.66666667, 0.33333333, 0.67857143,\n",
       "       0.91666667, 0.        , 0.66666667, 0.33333333, 0.        ,\n",
       "       0.5       ])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_per_label=[]\n",
    "\n",
    "accuracy_per_label=confusion_matrix(test_pred4, test_label)/testlabel_count\n",
    "accuracy_per_label.diagonal()\n",
    "accuracy_per_label=confusion_matrix(test_pred5, test_label)/testlabel_count\n",
    "accuracy_per_label.diagonal()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pred1\n",
    "array([0.65909091, 0.83333333, 0.        , 0.8       , 0.08333333,\n",
    "       0.59375   , 0.8       , 0.625     , 0.5       , 0.71428571,\n",
    "       0.91666667, 0.        , 0.76666667, 0.66666667, 0.66666667,\n",
    "       1.        ])\n",
    "       \n",
    "pred2\n",
    "array([0.61363636, 0.66666667, 0.        , 0.4       , 0.        ,\n",
    "       0.4375    , 0.8       , 0.83333333, 0.5       , 0.57142857,\n",
    "       0.60416667, 0.        , 0.58333333, 0.66666667, 1.        ,\n",
    "       1.        ])\n",
    "\n",
    "pred3\n",
    "array([0.90909091, 1.        , 0.        , 1.        , 0.66666667,\n",
    "       0.625     , 0.9       , 0.83333333, 0.66666667, 0.71428571,\n",
    "       1.        , 0.        , 0.73333333, 0.66666667, 1.        ,\n",
    "       0.75      ])\n",
    "pred4\n",
    "array([0.90909091, 1.        , 0.        , 0.8       , 0.66666667,\n",
    "       0.71875   , 0.9       , 0.83333333, 0.54166667, 0.85714286,\n",
    "       1.        , 0.        , 0.78333333, 0.66666667, 1.        ,\n",
    "       0.75      ])\n",
    "\n",
    "pred5\n",
    "array([0.72727273, 0.75      , 0.5       , 0.6       , 0.33333333,\n",
    "       0.5       , 0.625     , 0.83333333, 0.33333333, 0.67857143,\n",
    "       0.91666667, 0.        , 0.73333333, 0.33333333, 0.        ,\n",
    "       1.        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=[2,11,8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
