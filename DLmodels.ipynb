{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from datetime import datetime\n",
    "import keras\n",
    "import glob\n",
    "import random\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, LSTM, TimeDistributed, ConvLSTM2D\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def load_data():\n",
    "    filename_queue=glob.glob('./rawdata/data[1-6].csv')\n",
    "    \n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    trainX=[]\n",
    "    testX=[]\n",
    "    trainY=[]\n",
    "    testY=[]\n",
    "    label_count=np.zeros(16)\n",
    "\n",
    "    for filename in filename_queue:\n",
    "        file=open(filename, newline='')\n",
    "        reader=csv.reader(file)\n",
    "        header=next(reader)\n",
    "        read = list(reader)\n",
    "        random.shuffle(read)\n",
    "\n",
    "        for row in read:\n",
    "            row[4:]=[float(i) for i in row[4:]]\n",
    "            date=datetime.strptime(row[0],'%Y/%m/%d')\n",
    "            label=int(row[3])\n",
    "            label_count[label]+=1\n",
    "\n",
    "            for x in range(4):\n",
    "                X_acc=list(row[4*i+4+x] for i in range(150))\n",
    "                Y_acc=list(row[4*i+604+x] for i in range(150))\n",
    "                Z_acc=list(row[4*i+1204+x] for i in range(150))\n",
    "                X_gyro=list(row[4*i+1804+x] for i in range(150))\n",
    "                Y_gyro=list(row[4*i+2404+x] for i in range(150))\n",
    "                Z_gyro=list(row[4*i+3004+x] for i in range(150))\n",
    "\n",
    "                window=np.array([X_acc[0:150],Y_acc[0:150],Z_acc[0:150], X_gyro[0:150], Y_gyro[0:150], Z_gyro[0:150]])\n",
    "                window = np.transpose(window)\n",
    "\n",
    "                if (label_count[label]%5!=1):\n",
    "                    trainX.append(window)\n",
    "                    trainY.append(label)\n",
    "                else:\n",
    "                    testX.append(window)\n",
    "                    testY.append(label)\n",
    "\n",
    "    trainX = np.stack(trainX, axis = 0)\n",
    "    trainY = np.stack(trainY, axis = 0)\n",
    "\n",
    "    testX = np.stack(testX, axis = 0)\n",
    "    testY = np.stack(testY, axis = 0)\n",
    "    #one-hot encode\n",
    "    trainY = to_categorical(trainY)\n",
    "    testY = to_categorical(testY)\n",
    "\n",
    "    #trainX=trainX.reshape()\n",
    "\n",
    "#     print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/parkj0/anaconda3/envs/venv/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/parkj0/anaconda3/envs/venv/lib/python3.7/site-packages/Keras-2.2.4-py3.7.egg/keras/backend/tensorflow_backend.py:3721: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/parkj0/anaconda3/envs/venv/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "mean acc: 0.784375\n"
     ]
    }
   ],
   "source": [
    "#CNN-LSTM\n",
    "\n",
    "accs = []\n",
    "# [TUNING needed]\n",
    "n_lstm_cell = 64 #number of lstm cells\n",
    "epochs=32 #training epoch\n",
    "n_fc_cell = 32 #numer of fc layer cells\n",
    "dropout = 0.4 #dropout rate\n",
    "pool_size=1\n",
    "batch_size = 32\n",
    "\n",
    "for cv in range(1,6):\n",
    "    trainX, trainY, testX, testY = load_data()\n",
    "    n_steps, n_length = 30,5 \n",
    "    verbose = 0 #make verbose 1 if you want to see the training logs\n",
    "    \n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainY.shape[1]\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    \n",
    "    #configure model\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), input_shape=(None,n_length,n_features)))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "    model.add(TimeDistributed(Dropout(dropout)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=pool_size)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(n_lstm_cell))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(n_fc_cell, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    \n",
    "    #compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    #training model\n",
    "    tb_hist = keras.callbacks.TensorBoard(log_dir='./graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "    \n",
    "    model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, verbose=verbose,callbacks=[tb_hist])\n",
    "    _, accuracy = model.evaluate(testX, testY, batch_size=batch_size, verbose=0)\n",
    "    accs.append(accuracy)\n",
    "    #print(\"cross_val {}: {}\".format(cv, accuracy))\n",
    "print(\"mean acc: {}\".format(np.mean(accs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple CNN \n",
    "\n",
    "accs = []\n",
    "# [TUNING needed]\n",
    "n_conv = 3 #convolutional layer count\n",
    "epochs=20 #training epoch\n",
    "n_fc_cell = 128 #numer of fc layer cells\n",
    "dropout = 0.4 #dropout rate\n",
    "batch_size = 32\n",
    "pool_size=1\n",
    "\n",
    "for cv in range(1,6):\n",
    "    trainX, trainY, testX, testY = load_data()\n",
    "    verbose = 0 #make verbose 1 if you want to see the training logs\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainY.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "    for _ in range(n_conv-1):\n",
    "        model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_fc_cell, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    _, accuracy = model.evaluate(testX, testY, batch_size=batch_size, verbose=0)\n",
    "    accs.append(accuracy)\n",
    "     print(\"cross_val {}: {}\".format(cv, accuracy))\n",
    "print(\"mean acc: {}\".format(np.mean(accs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### don't care for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple LSTM  (very slow training! don't care for now)\n",
    "\n",
    "accs = []\n",
    "\n",
    "# [TUNING needed]\n",
    "n_lstm_cell = 128 #number of lstm cells\n",
    "epochs=32 #training epoch\n",
    "n_fc_cell = 32 #numer of fc layer cells\n",
    "dropout = 0.4 #dropout rate\n",
    "batch_size = 32\n",
    "\n",
    "for cv in range(1,6):\n",
    "    trainX, trainY, testX, testY = load_data()\n",
    "    verbose = 0 #make verbose 1 if you want to see the training logs\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainY.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_lstm_cell, input_shape=(n_timesteps, n_features)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(n_fc_cell, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    _, accuracy = model.evaluate(testX, testY, batch_size=batch_size, verbose=0)\n",
    "    accs.append(accuracy)\n",
    "#     print(\"cross_val {}: {}\".format(cv, accuracy))\n",
    "print(\"mean acc: {}\".format(np.mean(accs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "\n",
    "from joblib import dump, load\n",
    "filename='./context_.sav'\n",
    "pickle.dump(SVC,open(filename,'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
